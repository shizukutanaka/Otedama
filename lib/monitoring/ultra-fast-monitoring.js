/**
 * Ultra Fast Monitoring System - Otedama v1.1.8
 * 超高速モニタリングシステム
 * 
 * Features:
 * - Zero-allocation logging
 * - Binary log format
 * - Asynchronous metric collection
 * - Lock-free data structures
 * - Real-time dashboards
 */

import fs from 'fs/promises';
import { createWriteStream } from 'fs';
import { EventEmitter } from 'events';
import { createStructuredLogger } from '../core/structured-logger.js';
import { LockFreeQueue } from '../optimization/ultra-performance-optimizer.js';
import { memoryManager } from '../core/memory-manager.js';
import path from 'path';
import os from 'os';

const logger = createStructuredLogger('UltraFastMonitoring');

/**
 * High-performance binary logger
 */
export class BinaryLogger {
  constructor(options = {}) {
    this.options = {
      logDir: options.logDir || './logs',
      maxFileSize: options.maxFileSize || 100 * 1024 * 1024, // 100MB
      maxFiles: options.maxFiles || 10,\n      bufferSize: options.bufferSize || 64 * 1024, // 64KB\n      flushInterval: options.flushInterval || 1000, // 1 second\n      enableCompression: options.enableCompression || false,\n      ...options\n    };\n    \n    // Binary format constants\n    this.LOG_LEVELS = {\n      DEBUG: 0,\n      INFO: 1,\n      WARN: 2,\n      ERROR: 3,\n      FATAL: 4\n    };\n    \n    // Pre-allocated buffers\n    this.writeBuffer = Buffer.allocUnsafeSlow(this.options.bufferSize);\n    this.writeOffset = 0;\n    \n    // File management\n    this.currentFile = null;\n    this.currentFileSize = 0;\n    this.currentFileIndex = 0;\n    \n    // Performance counters\n    this.stats = {\n      totalLogs: 0,\n      totalBytes: 0,\n      flushes: 0,\n      avgLogSize: 0,\n      throughput: 0\n    };\n    \n    this.initialize();\n  }\n  \n  /**\n   * Initialize binary logger\n   */\n  async initialize() {\n    // Ensure log directory exists\n    await this.ensureLogDirectory();\n    \n    // Open initial log file\n    await this.openLogFile();\n    \n    // Start flush timer\n    this.flushTimer = setInterval(() => {\n      this.flush();\n    }, this.options.flushInterval);\n    \n    logger.info('Binary logger initialized', {\n      logDir: this.options.logDir,\n      bufferSize: this.options.bufferSize\n    });\n  }\n  \n  /**\n   * Ensure log directory exists\n   */\n  async ensureLogDirectory() {\n    try {\n      await fs.access(this.options.logDir);\n    } catch {\n      await fs.mkdir(this.options.logDir, { recursive: true });\n    }\n  }\n  \n  /**\n   * Open new log file\n   */\n  async openLogFile() {\n    if (this.currentFile) {\n      this.currentFile.end();\n    }\n    \n    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\n    const filename = `otedama-${timestamp}-${this.currentFileIndex}.binlog`;\n    const filepath = path.join(this.options.logDir, filename);\n    \n    this.currentFile = createWriteStream(filepath, { flags: 'w' });\n    this.currentFileSize = 0;\n    \n    // Write file header\n    await this.writeFileHeader();\n  }\n  \n  /**\n   * Write binary file header\n   */\n  async writeFileHeader() {\n    const header = Buffer.allocUnsafeSlow(32);\n    let offset = 0;\n    \n    // Magic bytes: \"OTBL\" (Otedama Binary Log)\n    header.write('OTBL', offset, 'ascii');\n    offset += 4;\n    \n    // Version\n    header.writeUInt16LE(1, offset);\n    offset += 2;\n    \n    // Creation timestamp\n    header.writeBigUInt64LE(BigInt(Date.now()), offset);\n    offset += 8;\n    \n    // Node.js version\n    const nodeVersion = process.version.slice(1); // Remove 'v'\n    header.write(nodeVersion.padEnd(18, '\\0'), offset, 'ascii');\n    \n    this.currentFile.write(header);\n    this.currentFileSize += 32;\n  }\n  \n  /**\n   * Log message in binary format\n   */\n  log(level, message, metadata = {}) {\n    const startTime = performance.now();\n    \n    try {\n      // Serialize log entry\n      const serialized = this.serializeLogEntry(level, message, metadata);\n      \n      // Check buffer space\n      if (this.writeOffset + serialized.length > this.options.bufferSize) {\n        this.flush();\n      }\n      \n      // Copy to write buffer\n      serialized.copy(this.writeBuffer, this.writeOffset);\n      this.writeOffset += serialized.length;\n      \n      // Update statistics\n      this.stats.totalLogs++;\n      this.stats.totalBytes += serialized.length;\n      this.stats.avgLogSize = this.stats.totalBytes / this.stats.totalLogs;\n      \n      const elapsed = performance.now() - startTime;\n      this.stats.throughput = this.stats.totalLogs / (Date.now() / 1000);\n      \n    } catch (error) {\n      console.error('Binary logging failed:', error);\n    }\n  }\n  \n  /**\n   * Serialize log entry to binary format\n   */\n  serializeLogEntry(level, message, metadata) {\n    const timestamp = Date.now();\n    const messageBuffer = Buffer.from(message, 'utf8');\n    const metadataBuffer = Buffer.from(JSON.stringify(metadata), 'utf8');\n    \n    // Calculate total size\n    const totalSize = \n      4 +  // entry size\n      8 +  // timestamp\n      1 +  // level\n      4 +  // message length\n      messageBuffer.length +\n      4 +  // metadata length\n      metadataBuffer.length;\n    \n    const buffer = Buffer.allocUnsafeSlow(totalSize);\n    let offset = 0;\n    \n    // Entry size (for reading backwards)\n    buffer.writeUInt32LE(totalSize, offset);\n    offset += 4;\n    \n    // Timestamp\n    buffer.writeBigUInt64LE(BigInt(timestamp), offset);\n    offset += 8;\n    \n    // Log level\n    buffer.writeUInt8(this.LOG_LEVELS[level] || 1, offset);\n    offset += 1;\n    \n    // Message\n    buffer.writeUInt32LE(messageBuffer.length, offset);\n    offset += 4;\n    messageBuffer.copy(buffer, offset);\n    offset += messageBuffer.length;\n    \n    // Metadata\n    buffer.writeUInt32LE(metadataBuffer.length, offset);\n    offset += 4;\n    metadataBuffer.copy(buffer, offset);\n    \n    return buffer;\n  }\n  \n  /**\n   * Flush buffer to disk\n   */\n  async flush() {\n    if (this.writeOffset === 0) return;\n    \n    try {\n      // Write buffered data\n      const dataToWrite = this.writeBuffer.slice(0, this.writeOffset);\n      this.currentFile.write(dataToWrite);\n      \n      this.currentFileSize += this.writeOffset;\n      this.writeOffset = 0;\n      this.stats.flushes++;\n      \n      // Check if file rotation is needed\n      if (this.currentFileSize > this.options.maxFileSize) {\n        await this.rotateLogFile();\n      }\n      \n    } catch (error) {\n      console.error('Log flush failed:', error);\n    }\n  }\n  \n  /**\n   * Rotate log file\n   */\n  async rotateLogFile() {\n    this.currentFileIndex++;\n    await this.openLogFile();\n    \n    // Clean up old files if needed\n    await this.cleanupOldLogs();\n  }\n  \n  /**\n   * Clean up old log files\n   */\n  async cleanupOldLogs() {\n    try {\n      const files = await fs.readdir(this.options.logDir);\n      const logFiles = files\n        .filter(f => f.endsWith('.binlog'))\n        .sort()\n        .reverse(); // Newest first\n      \n      if (logFiles.length > this.options.maxFiles) {\n        const filesToDelete = logFiles.slice(this.options.maxFiles);\n        \n        for (const file of filesToDelete) {\n          await fs.unlink(path.join(this.options.logDir, file));\n        }\n        \n        logger.debug(`Cleaned up ${filesToDelete.length} old log files`);\n      }\n    } catch (error) {\n      console.error('Log cleanup failed:', error);\n    }\n  }\n  \n  /**\n   * Get logger statistics\n   */\n  getStats() {\n    return {\n      ...this.stats,\n      bufferUsage: this.writeOffset / this.options.bufferSize,\n      currentFileSize: this.currentFileSize,\n      currentFileIndex: this.currentFileIndex\n    };\n  }\n  \n  /**\n   * Shutdown logger\n   */\n  async shutdown() {\n    if (this.flushTimer) {\n      clearInterval(this.flushTimer);\n    }\n    \n    await this.flush();\n    \n    if (this.currentFile) {\n      this.currentFile.end();\n    }\n    \n    logger.info('Binary logger shutdown completed');\n  }\n}\n\n/**\n * Lock-free metrics collector\n */\nexport class LockFreeMetricsCollector extends EventEmitter {\n  constructor(options = {}) {\n    super();\n    \n    this.options = {\n      maxMetrics: options.maxMetrics || 10000,\n      aggregationInterval: options.aggregationInterval || 5000, // 5 seconds\n      retentionPeriod: options.retentionPeriod || 3600000, // 1 hour\n      enableHistograms: options.enableHistograms !== false,\n      ...options\n    };\n    \n    // Lock-free data structures\n    this.metricsQueue = new LockFreeQueue(this.options.maxMetrics);\n    this.aggregatedMetrics = new Map();\n    \n    // Metric types\n    this.counters = new Map();\n    this.gauges = new Map();\n    this.histograms = new Map();\n    this.timers = new Map();\n    \n    // Performance tracking\n    this.stats = {\n      totalMetrics: 0,\n      droppedMetrics: 0,\n      aggregations: 0,\n      avgAggregationTime: 0\n    };\n    \n    this.initialize();\n  }\n  \n  /**\n   * Initialize metrics collector\n   */\n  initialize() {\n    // Start aggregation timer\n    this.aggregationTimer = setInterval(() => {\n      this.aggregate();\n    }, this.options.aggregationInterval);\n    \n    // Start cleanup timer\n    this.cleanupTimer = setInterval(() => {\n      this.cleanup();\n    }, this.options.retentionPeriod / 4);\n    \n    logger.info('Lock-free metrics collector initialized', {\n      maxMetrics: this.options.maxMetrics,\n      aggregationInterval: this.options.aggregationInterval\n    });\n  }\n  \n  /**\n   * Increment counter\n   */\n  increment(name, value = 1, tags = {}) {\n    const metric = {\n      type: 'counter',\n      name,\n      value,\n      tags,\n      timestamp: Date.now()\n    };\n    \n    if (!this.metricsQueue.enqueue(metric)) {\n      this.stats.droppedMetrics++;\n    } else {\n      this.stats.totalMetrics++;\n    }\n  }\n  \n  /**\n   * Set gauge value\n   */\n  gauge(name, value, tags = {}) {\n    const metric = {\n      type: 'gauge',\n      name,\n      value,\n      tags,\n      timestamp: Date.now()\n    };\n    \n    if (!this.metricsQueue.enqueue(metric)) {\n      this.stats.droppedMetrics++;\n    } else {\n      this.stats.totalMetrics++;\n    }\n  }\n  \n  /**\n   * Record histogram value\n   */\n  histogram(name, value, tags = {}) {\n    const metric = {\n      type: 'histogram',\n      name,\n      value,\n      tags,\n      timestamp: Date.now()\n    };\n    \n    if (!this.metricsQueue.enqueue(metric)) {\n      this.stats.droppedMetrics++;\n    } else {\n      this.stats.totalMetrics++;\n    }\n  }\n  \n  /**\n   * Time function execution\n   */\n  time(name, fn, tags = {}) {\n    const startTime = performance.now();\n    \n    try {\n      const result = fn();\n      \n      // Handle async functions\n      if (result && typeof result.then === 'function') {\n        return result.finally(() => {\n          const elapsed = performance.now() - startTime;\n          this.histogram(name, elapsed, tags);\n        });\n      } else {\n        const elapsed = performance.now() - startTime;\n        this.histogram(name, elapsed, tags);\n        return result;\n      }\n    } catch (error) {\n      const elapsed = performance.now() - startTime;\n      this.histogram(name, elapsed, { ...tags, error: true });\n      throw error;\n    }\n  }\n  \n  /**\n   * Start timer\n   */\n  startTimer(name, tags = {}) {\n    const timerId = `${name}_${Date.now()}_${Math.random()}`;\n    this.timers.set(timerId, {\n      name,\n      tags,\n      startTime: performance.now()\n    });\n    \n    return {\n      stop: () => {\n        const timer = this.timers.get(timerId);\n        if (timer) {\n          const elapsed = performance.now() - timer.startTime;\n          this.histogram(timer.name, elapsed, timer.tags);\n          this.timers.delete(timerId);\n          return elapsed;\n        }\n        return 0;\n      }\n    };\n  }\n  \n  /**\n   * Aggregate metrics from queue\n   */\n  aggregate() {\n    const startTime = performance.now();\n    let processed = 0;\n    \n    // Process all queued metrics\n    while (!this.metricsQueue.isEmpty() && processed < 1000) {\n      const metric = this.metricsQueue.dequeue();\n      if (!metric) break;\n      \n      this.processMetric(metric);\n      processed++;\n    }\n    \n    // Emit aggregated metrics\n    if (processed > 0) {\n      this.emitAggregatedMetrics();\n    }\n    \n    // Update stats\n    const elapsed = performance.now() - startTime;\n    this.stats.aggregations++;\n    this.stats.avgAggregationTime = \n      (this.stats.avgAggregationTime * (this.stats.aggregations - 1) + elapsed) / \n      this.stats.aggregations;\n  }\n  \n  /**\n   * Process individual metric\n   */\n  processMetric(metric) {\n    const key = this.getMetricKey(metric);\n    \n    switch (metric.type) {\n      case 'counter':\n        this.processCounter(key, metric);\n        break;\n      case 'gauge':\n        this.processGauge(key, metric);\n        break;\n      case 'histogram':\n        this.processHistogram(key, metric);\n        break;\n    }\n  }\n  \n  /**\n   * Process counter metric\n   */\n  processCounter(key, metric) {\n    const existing = this.counters.get(key);\n    \n    if (existing) {\n      existing.value += metric.value;\n      existing.lastUpdate = metric.timestamp;\n    } else {\n      this.counters.set(key, {\n        name: metric.name,\n        value: metric.value,\n        tags: metric.tags,\n        lastUpdate: metric.timestamp\n      });\n    }\n  }\n  \n  /**\n   * Process gauge metric\n   */\n  processGauge(key, metric) {\n    this.gauges.set(key, {\n      name: metric.name,\n      value: metric.value,\n      tags: metric.tags,\n      lastUpdate: metric.timestamp\n    });\n  }\n  \n  /**\n   * Process histogram metric\n   */\n  processHistogram(key, metric) {\n    if (!this.options.enableHistograms) return;\n    \n    const existing = this.histograms.get(key);\n    \n    if (existing) {\n      existing.values.push(metric.value);\n      existing.count++;\n      existing.sum += metric.value;\n      existing.min = Math.min(existing.min, metric.value);\n      existing.max = Math.max(existing.max, metric.value);\n      existing.lastUpdate = metric.timestamp;\n      \n      // Keep only recent values to save memory\n      if (existing.values.length > 1000) {\n        existing.values = existing.values.slice(-500);\n      }\n    } else {\n      this.histograms.set(key, {\n        name: metric.name,\n        values: [metric.value],\n        count: 1,\n        sum: metric.value,\n        min: metric.value,\n        max: metric.value,\n        tags: metric.tags,\n        lastUpdate: metric.timestamp\n      });\n    }\n  }\n  \n  /**\n   * Generate metric key\n   */\n  getMetricKey(metric) {\n    const tagString = Object.entries(metric.tags)\n      .sort(([a], [b]) => a.localeCompare(b))\n      .map(([k, v]) => `${k}=${v}`)\n      .join(',');\n    \n    return `${metric.name}${tagString ? `{${tagString}}` : ''}`;\n  }\n  \n  /**\n   * Emit aggregated metrics\n   */\n  emitAggregatedMetrics() {\n    const metrics = {\n      counters: Array.from(this.counters.entries()).map(([key, value]) => ({ key, ...value })),\n      gauges: Array.from(this.gauges.entries()).map(([key, value]) => ({ key, ...value })),\n      histograms: Array.from(this.histograms.entries()).map(([key, histogram]) => {\n        const values = histogram.values.sort((a, b) => a - b);\n        const count = values.length;\n        \n        return {\n          key,\n          name: histogram.name,\n          tags: histogram.tags,\n          count: histogram.count,\n          sum: histogram.sum,\n          min: histogram.min,\n          max: histogram.max,\n          avg: histogram.sum / histogram.count,\n          p50: count > 0 ? values[Math.floor(count * 0.5)] : 0,\n          p95: count > 0 ? values[Math.floor(count * 0.95)] : 0,\n          p99: count > 0 ? values[Math.floor(count * 0.99)] : 0,\n          lastUpdate: histogram.lastUpdate\n        };\n      })\n    };\n    \n    this.emit('metrics', metrics);\n  }\n  \n  /**\n   * Clean up old metrics\n   */\n  cleanup() {\n    const now = Date.now();\n    const cutoff = now - this.options.retentionPeriod;\n    \n    let cleaned = 0;\n    \n    // Clean counters\n    for (const [key, counter] of this.counters.entries()) {\n      if (counter.lastUpdate < cutoff) {\n        this.counters.delete(key);\n        cleaned++;\n      }\n    }\n    \n    // Clean gauges\n    for (const [key, gauge] of this.gauges.entries()) {\n      if (gauge.lastUpdate < cutoff) {\n        this.gauges.delete(key);\n        cleaned++;\n      }\n    }\n    \n    // Clean histograms\n    for (const [key, histogram] of this.histograms.entries()) {\n      if (histogram.lastUpdate < cutoff) {\n        this.histograms.delete(key);\n        cleaned++;\n      }\n    }\n    \n    if (cleaned > 0) {\n      logger.debug(`Cleaned up ${cleaned} old metrics`);\n    }\n  }\n  \n  /**\n   * Get current metrics snapshot\n   */\n  getMetrics() {\n    this.emitAggregatedMetrics();\n    \n    return {\n      counters: Object.fromEntries(this.counters),\n      gauges: Object.fromEntries(this.gauges),\n      histograms: Object.fromEntries(this.histograms)\n    };\n  }\n  \n  /**\n   * Get collector statistics\n   */\n  getStats() {\n    return {\n      ...this.stats,\n      queueSize: this.metricsQueue.size(),\n      counters: this.counters.size,\n      gauges: this.gauges.size,\n      histograms: this.histograms.size,\n      timers: this.timers.size\n    };\n  }\n  \n  /**\n   * Shutdown metrics collector\n   */\n  shutdown() {\n    if (this.aggregationTimer) {\n      clearInterval(this.aggregationTimer);\n    }\n    \n    if (this.cleanupTimer) {\n      clearInterval(this.cleanupTimer);\n    }\n    \n    // Final aggregation\n    this.aggregate();\n    \n    logger.info('Lock-free metrics collector shutdown completed');\n  }\n}\n\n/**\n * Real-time system monitor\n */\nexport class SystemMonitor extends EventEmitter {\n  constructor(options = {}) {\n    super();\n    \n    this.options = {\n      interval: options.interval || 5000, // 5 seconds\n      enableDetailed: options.enableDetailed !== false,\n      thresholds: {\n        cpu: options.thresholds?.cpu || 80,\n        memory: options.thresholds?.memory || 85,\n        disk: options.thresholds?.disk || 90,\n        ...options.thresholds\n      },\n      ...options\n    };\n    \n    this.history = [];\n    this.maxHistory = 100;\n    \n    this.initialize();\n  }\n  \n  /**\n   * Initialize system monitor\n   */\n  initialize() {\n    this.timer = setInterval(() => {\n      this.collectSystemMetrics();\n    }, this.options.interval);\n    \n    logger.info('System monitor initialized', {\n      interval: this.options.interval,\n      thresholds: this.options.thresholds\n    });\n  }\n  \n  /**\n   * Collect system metrics\n   */\n  async collectSystemMetrics() {\n    try {\n      const metrics = {\n        timestamp: Date.now(),\n        process: this.getProcessMetrics(),\n        system: this.getSystemMetrics(),\n        v8: this.getV8Metrics()\n      };\n      \n      // Add to history\n      this.history.push(metrics);\n      if (this.history.length > this.maxHistory) {\n        this.history.shift();\n      }\n      \n      // Check thresholds\n      this.checkThresholds(metrics);\n      \n      // Emit metrics\n      this.emit('metrics', metrics);\n      \n    } catch (error) {\n      logger.error('System metrics collection failed', { error: error.message });\n    }\n  }\n  \n  /**\n   * Get process metrics\n   */\n  getProcessMetrics() {\n    const memUsage = process.memoryUsage();\n    const cpuUsage = process.cpuUsage();\n    \n    return {\n      pid: process.pid,\n      uptime: process.uptime(),\n      memory: {\n        rss: memUsage.rss,\n        heapTotal: memUsage.heapTotal,\n        heapUsed: memUsage.heapUsed,\n        heapUsedPercent: (memUsage.heapUsed / memUsage.heapTotal) * 100,\n        external: memUsage.external,\n        arrayBuffers: memUsage.arrayBuffers || 0\n      },\n      cpu: {\n        user: cpuUsage.user,\n        system: cpuUsage.system\n      }\n    };\n  }\n  \n  /**\n   * Get system metrics\n   */\n  getSystemMetrics() {\n    const totalMem = os.totalmem();\n    const freeMem = os.freemem();\n    const usedMem = totalMem - freeMem;\n    \n    return {\n      platform: os.platform(),\n      arch: os.arch(),\n      cpus: os.cpus().length,\n      loadavg: os.loadavg(),\n      memory: {\n        total: totalMem,\n        free: freeMem,\n        used: usedMem,\n        usedPercent: (usedMem / totalMem) * 100\n      },\n      uptime: os.uptime()\n    };\n  }\n  \n  /**\n   * Get V8 metrics\n   */\n  getV8Metrics() {\n    try {\n      const v8 = require('v8');\n      const heapStats = v8.getHeapStatistics();\n      const heapSpaceStats = v8.getHeapSpaceStatistics();\n      \n      return {\n        heap: heapStats,\n        heapSpaces: heapSpaceStats\n      };\n    } catch (error) {\n      return null;\n    }\n  }\n  \n  /**\n   * Check metric thresholds\n   */\n  checkThresholds(metrics) {\n    const alerts = [];\n    \n    // Memory threshold\n    if (metrics.process.memory.heapUsedPercent > this.options.thresholds.memory) {\n      alerts.push({\n        type: 'memory',\n        severity: 'warning',\n        value: metrics.process.memory.heapUsedPercent,\n        threshold: this.options.thresholds.memory,\n        message: `Heap memory usage is ${metrics.process.memory.heapUsedPercent.toFixed(1)}%`\n      });\n    }\n    \n    // System memory threshold\n    if (metrics.system.memory.usedPercent > this.options.thresholds.memory) {\n      alerts.push({\n        type: 'system_memory',\n        severity: 'warning',\n        value: metrics.system.memory.usedPercent,\n        threshold: this.options.thresholds.memory,\n        message: `System memory usage is ${metrics.system.memory.usedPercent.toFixed(1)}%`\n      });\n    }\n    \n    // CPU load threshold (using 1-minute load average)\n    const cpuLoadPercent = (metrics.system.loadavg[0] / metrics.system.cpus) * 100;\n    if (cpuLoadPercent > this.options.thresholds.cpu) {\n      alerts.push({\n        type: 'cpu',\n        severity: 'warning',\n        value: cpuLoadPercent,\n        threshold: this.options.thresholds.cpu,\n        message: `CPU load is ${cpuLoadPercent.toFixed(1)}%`\n      });\n    }\n    \n    // Emit alerts\n    if (alerts.length > 0) {\n      this.emit('alerts', alerts);\n    }\n  }\n  \n  /**\n   * Get system metrics history\n   */\n  getHistory(minutes = 10) {\n    const cutoff = Date.now() - (minutes * 60 * 1000);\n    return this.history.filter(m => m.timestamp >= cutoff);\n  }\n  \n  /**\n   * Get current system status\n   */\n  getStatus() {\n    if (this.history.length === 0) {\n      return { status: 'initializing' };\n    }\n    \n    const latest = this.history[this.history.length - 1];\n    const memPercent = latest.process.memory.heapUsedPercent;\n    const sysMemPercent = latest.system.memory.usedPercent;\n    const cpuLoadPercent = (latest.system.loadavg[0] / latest.system.cpus) * 100;\n    \n    let status = 'healthy';\n    const issues = [];\n    \n    if (memPercent > this.options.thresholds.memory || \n        sysMemPercent > this.options.thresholds.memory) {\n      status = 'warning';\n      issues.push('high_memory');\n    }\n    \n    if (cpuLoadPercent > this.options.thresholds.cpu) {\n      status = 'warning';\n      issues.push('high_cpu');\n    }\n    \n    if (memPercent > 95 || sysMemPercent > 95 || cpuLoadPercent > 95) {\n      status = 'critical';\n    }\n    \n    return {\n      status,\n      issues,\n      metrics: {\n        memory: memPercent,\n        systemMemory: sysMemPercent,\n        cpu: cpuLoadPercent\n      },\n      lastUpdate: latest.timestamp\n    };\n  }\n  \n  /**\n   * Shutdown system monitor\n   */\n  shutdown() {\n    if (this.timer) {\n      clearInterval(this.timer);\n    }\n    \n    logger.info('System monitor shutdown completed');\n  }\n}\n\nexport default {\n  BinaryLogger,\n  LockFreeMetricsCollector,\n  SystemMonitor\n};"