/**
 * Ultra Async Engine - Otedama v1.1.8
 * 超高速非同期処理エンジン
 * 
 * Features:
 * - Lock-free async operations
 * - Adaptive work stealing
 * - Event loop optimization
 * - Coroutine-style async/await
 * - Priority-based task scheduling
 */

import { Worker, isMainThread, parentPort, workerData } from 'worker_threads';
import { EventEmitter } from 'events';
import { createStructuredLogger } from '../core/structured-logger.js';
import { LockFreeQueue } from '../optimization/ultra-performance-optimizer.js';
import os from 'os';

const logger = createStructuredLogger('UltraAsyncEngine');

/**
 * Task priority levels
 */
export const TASK_PRIORITY = {
  CRITICAL: 0,    // Mining operations
  HIGH: 1,        // Network I/O
  NORMAL: 2,      // General processing
  LOW: 3,         // Background cleanup
  IDLE: 4         // Maintenance tasks
};

/**
 * Lock-free priority queue for tasks
 */
export class PriorityTaskQueue {
  constructor(maxSize = 10000) {
    // Separate queues for each priority level
    this.queues = {
      [TASK_PRIORITY.CRITICAL]: new LockFreeQueue(maxSize / 5),
      [TASK_PRIORITY.HIGH]: new LockFreeQueue(maxSize / 5),
      [TASK_PRIORITY.NORMAL]: new LockFreeQueue(maxSize / 2),
      [TASK_PRIORITY.LOW]: new LockFreeQueue(maxSize / 10),
      [TASK_PRIORITY.IDLE]: new LockFreeQueue(maxSize / 10)
    };\n    \n    this.stats = {\n      totalEnqueued: 0,\n      totalDequeued: 0,\n      priorityDistribution: {\n        [TASK_PRIORITY.CRITICAL]: 0,\n        [TASK_PRIORITY.HIGH]: 0,\n        [TASK_PRIORITY.NORMAL]: 0,\n        [TASK_PRIORITY.LOW]: 0,\n        [TASK_PRIORITY.IDLE]: 0\n      }\n    };\n  }\n  \n  /**\n   * Enqueue task with priority\n   */\n  enqueue(task, priority = TASK_PRIORITY.NORMAL) {\n    const queue = this.queues[priority];\n    if (!queue) {\n      throw new Error(`Invalid priority: ${priority}`);\n    }\n    \n    const success = queue.enqueue({\n      ...task,\n      priority,\n      enqueuedAt: performance.now()\n    });\n    \n    if (success) {\n      this.stats.totalEnqueued++;\n      this.stats.priorityDistribution[priority]++;\n    }\n    \n    return success;\n  }\n  \n  /**\n   * Dequeue highest priority task\n   */\n  dequeue() {\n    // Check queues in priority order\n    for (const priority of [TASK_PRIORITY.CRITICAL, TASK_PRIORITY.HIGH, \n                           TASK_PRIORITY.NORMAL, TASK_PRIORITY.LOW, TASK_PRIORITY.IDLE]) {\n      const queue = this.queues[priority];\n      const task = queue.dequeue();\n      \n      if (task) {\n        this.stats.totalDequeued++;\n        task.dequeuedAt = performance.now();\n        task.waitTime = task.dequeuedAt - task.enqueuedAt;\n        return task;\n      }\n    }\n    \n    return null;\n  }\n  \n  /**\n   * Get total size across all queues\n   */\n  size() {\n    return Object.values(this.queues).reduce((total, queue) => total + queue.size(), 0);\n  }\n  \n  /**\n   * Check if all queues are empty\n   */\n  isEmpty() {\n    return Object.values(this.queues).every(queue => queue.isEmpty());\n  }\n  \n  /**\n   * Get queue statistics\n   */\n  getStats() {\n    const queueSizes = {};\n    for (const [priority, queue] of Object.entries(this.queues)) {\n      queueSizes[priority] = queue.size();\n    }\n    \n    return {\n      ...this.stats,\n      queueSizes,\n      totalSize: this.size()\n    };\n  }\n}\n\n/**\n * Work-stealing task scheduler\n */\nexport class WorkStealingScheduler extends EventEmitter {\n  constructor(options = {}) {\n    super();\n    \n    this.options = {\n      workerCount: options.workerCount || os.cpus().length,\n      stealThreshold: options.stealThreshold || 5,\n      maxTasksPerWorker: options.maxTasksPerWorker || 1000,\n      adaptiveScaling: options.adaptiveScaling !== false,\n      ...options\n    };\n    \n    // Per-worker task queues\n    this.workerQueues = [];\n    this.workers = [];\n    this.workerStats = [];\n    \n    // Global task queue for overflow\n    this.globalQueue = new PriorityTaskQueue(10000);\n    \n    // Load balancing\n    this.nextWorkerIndex = 0;\n    this.loadMetrics = {\n      totalTasks: 0,\n      completedTasks: 0,\n      avgExecutionTime: 0,\n      workerUtilization: []\n    };\n    \n    this.initialize();\n  }\n  \n  /**\n   * Initialize scheduler\n   */\n  initialize() {\n    // Create worker queues\n    for (let i = 0; i < this.options.workerCount; i++) {\n      this.workerQueues.push(new PriorityTaskQueue(this.options.maxTasksPerWorker));\n      this.workerStats.push({\n        tasksExecuted: 0,\n        tasksStolen: 0,\n        avgExecutionTime: 0,\n        utilization: 0,\n        lastActivity: Date.now()\n      });\n    }\n    \n    // Start work-stealing monitoring\n    this.stealingTimer = setInterval(() => {\n      this.performWorkStealing();\n    }, 10); // Check every 10ms for high responsiveness\n    \n    // Start adaptive scaling\n    if (this.options.adaptiveScaling) {\n      this.scalingTimer = setInterval(() => {\n        this.adaptiveScaling();\n      }, 1000); // Check every second\n    }\n    \n    logger.info('Work-stealing scheduler initialized', {\n      workerCount: this.options.workerCount,\n      stealThreshold: this.options.stealThreshold\n    });\n  }\n  \n  /**\n   * Schedule task to optimal worker\n   */\n  schedule(task, priority = TASK_PRIORITY.NORMAL) {\n    // Find worker with least load\n    let targetWorker = this.findOptimalWorker();\n    \n    // Try to enqueue to worker\n    const success = this.workerQueues[targetWorker].enqueue(task, priority);\n    \n    if (!success) {\n      // Worker queue full, try global queue\n      const globalSuccess = this.globalQueue.enqueue(task, priority);\n      if (!globalSuccess) {\n        logger.warn('Failed to schedule task - all queues full');\n        return false;\n      }\n    }\n    \n    this.loadMetrics.totalTasks++;\n    this.emit('taskScheduled', { task, worker: targetWorker, priority });\n    \n    return true;\n  }\n  \n  /**\n   * Find optimal worker for task assignment\n   */\n  findOptimalWorker() {\n    let minLoad = Infinity;\n    let optimalWorker = 0;\n    \n    for (let i = 0; i < this.workerQueues.length; i++) {\n      const load = this.calculateWorkerLoad(i);\n      if (load < minLoad) {\n        minLoad = load;\n        optimalWorker = i;\n      }\n    }\n    \n    return optimalWorker;\n  }\n  \n  /**\n   * Calculate worker load metric\n   */\n  calculateWorkerLoad(workerIndex) {\n    const queue = this.workerQueues[workerIndex];\n    const stats = this.workerStats[workerIndex];\n    \n    // Weighted load calculation\n    const queueLoad = queue.size() * 0.7;\n    const utilizationLoad = stats.utilization * 0.3;\n    \n    return queueLoad + utilizationLoad;\n  }\n  \n  /**\n   * Get task from worker queue (for worker consumption)\n   */\n  getTask(workerIndex) {\n    // First try own queue\n    let task = this.workerQueues[workerIndex].dequeue();\n    \n    if (!task) {\n      // Try to steal from global queue\n      task = this.globalQueue.dequeue();\n    }\n    \n    if (task) {\n      task.assignedWorker = workerIndex;\n      this.workerStats[workerIndex].lastActivity = Date.now();\n    }\n    \n    return task;\n  }\n  \n  /**\n   * Perform work stealing between workers\n   */\n  performWorkStealing() {\n    // Find overloaded and underloaded workers\n    const overloaded = [];\n    const underloaded = [];\n    \n    for (let i = 0; i < this.workerQueues.length; i++) {\n      const queueSize = this.workerQueues[i].size();\n      \n      if (queueSize > this.options.stealThreshold) {\n        overloaded.push({ index: i, size: queueSize });\n      } else if (queueSize === 0) {\n        underloaded.push({ index: i, size: queueSize });\n      }\n    }\n    \n    // Perform stealing\n    if (overloaded.length > 0 && underloaded.length > 0) {\n      this.stealTasks(overloaded, underloaded);\n    }\n  }\n  \n  /**\n   * Steal tasks from overloaded to underloaded workers\n   */\n  stealTasks(overloaded, underloaded) {\n    // Sort by load\n    overloaded.sort((a, b) => b.size - a.size);\n    \n    for (const victim of overloaded) {\n      if (underloaded.length === 0) break;\n      \n      const thief = underloaded.shift();\n      const tasksToSteal = Math.floor((victim.size - this.options.stealThreshold) / 2);\n      \n      let stolenTasks = 0;\n      \n      // Steal lower priority tasks first\n      for (let priority = TASK_PRIORITY.IDLE; priority >= TASK_PRIORITY.CRITICAL && stolenTasks < tasksToSteal; priority--) {\n        const victimQueue = this.workerQueues[victim.index].queues[priority];\n        const thiefQueue = this.workerQueues[thief.index].queues[priority];\n        \n        while (stolenTasks < tasksToSteal && !victimQueue.isEmpty()) {\n          const task = victimQueue.dequeue();\n          if (task && thiefQueue.enqueue(task)) {\n            stolenTasks++;\n            this.workerStats[thief.index].tasksStolen++;\n          }\n        }\n      }\n      \n      if (stolenTasks > 0) {\n        logger.debug(`Work stealing: ${stolenTasks} tasks from worker ${victim.index} to ${thief.index}`);\n        this.emit('workStolen', { victim: victim.index, thief: thief.index, count: stolenTasks });\n      }\n    }\n  }\n  \n  /**\n   * Report task completion (for statistics)\n   */\n  reportTaskCompletion(workerIndex, executionTime) {\n    const stats = this.workerStats[workerIndex];\n    stats.tasksExecuted++;\n    \n    // Update average execution time\n    stats.avgExecutionTime = (stats.avgExecutionTime * (stats.tasksExecuted - 1) + executionTime) / stats.tasksExecuted;\n    \n    // Update global metrics\n    this.loadMetrics.completedTasks++;\n    this.loadMetrics.avgExecutionTime = \n      (this.loadMetrics.avgExecutionTime * (this.loadMetrics.completedTasks - 1) + executionTime) / \n      this.loadMetrics.completedTasks;\n  }\n  \n  /**\n   * Adaptive scaling based on load\n   */\n  adaptiveScaling() {\n    const totalQueueSize = this.workerQueues.reduce((sum, queue) => sum + queue.size(), 0) + this.globalQueue.size();\n    const avgUtilization = this.workerStats.reduce((sum, stat) => sum + stat.utilization, 0) / this.workerStats.length;\n    \n    // Simple scaling logic\n    if (totalQueueSize > this.options.workerCount * 10 && avgUtilization > 0.8) {\n      // High load - consider scaling up\n      this.emit('scalingRecommendation', { action: 'scale_up', reason: 'high_load' });\n    } else if (totalQueueSize < this.options.workerCount * 2 && avgUtilization < 0.3) {\n      // Low load - consider scaling down\n      this.emit('scalingRecommendation', { action: 'scale_down', reason: 'low_load' });\n    }\n  }\n  \n  /**\n   * Get scheduler statistics\n   */\n  getStats() {\n    const queueStats = this.workerQueues.map(queue => queue.getStats());\n    const globalStats = this.globalQueue.getStats();\n    \n    return {\n      loadMetrics: this.loadMetrics,\n      workerStats: this.workerStats,\n      queueStats,\n      globalStats,\n      totalQueuedTasks: queueStats.reduce((sum, stat) => sum + stat.totalSize, 0) + globalStats.totalSize\n    };\n  }\n  \n  /**\n   * Shutdown scheduler\n   */\n  shutdown() {\n    if (this.stealingTimer) {\n      clearInterval(this.stealingTimer);\n    }\n    \n    if (this.scalingTimer) {\n      clearInterval(this.scalingTimer);\n    }\n    \n    logger.info('Work-stealing scheduler shutdown completed');\n  }\n}\n\n/**\n * Ultra-fast async executor\n */\nexport class UltraAsyncExecutor extends EventEmitter {\n  constructor(options = {}) {\n    super();\n    \n    this.options = {\n      maxConcurrency: options.maxConcurrency || os.cpus().length * 4,\n      queueSize: options.queueSize || 10000,\n      enableWorkStealing: options.enableWorkStealing !== false,\n      batchSize: options.batchSize || 100,\n      ...options\n    };\n    \n    // Task scheduling\n    if (this.options.enableWorkStealing) {\n      this.scheduler = new WorkStealingScheduler({\n        workerCount: this.options.maxConcurrency,\n        maxTasksPerWorker: this.options.queueSize / this.options.maxConcurrency\n      });\n    } else {\n      this.taskQueue = new PriorityTaskQueue(this.options.queueSize);\n    }\n    \n    // Execution context\n    this.activeExecutions = new Set();\n    this.executionPool = [];\n    \n    // Performance metrics\n    this.metrics = {\n      totalExecuted: 0,\n      totalErrors: 0,\n      avgExecutionTime: 0,\n      throughput: 0,\n      concurrentExecutions: 0\n    };\n    \n    this.initialize();\n  }\n  \n  /**\n   * Initialize executor\n   */\n  initialize() {\n    // Start execution loop\n    this.executionTimer = setInterval(() => {\n      this.processTaskBatch();\n    }, 1); // Process every 1ms for maximum responsiveness\n    \n    // Setup scheduler events\n    if (this.scheduler) {\n      this.scheduler.on('taskScheduled', (data) => {\n        this.emit('taskScheduled', data);\n      });\n      \n      this.scheduler.on('workStolen', (data) => {\n        this.emit('workStolen', data);\n      });\n    }\n    \n    logger.info('Ultra-async executor initialized', {\n      maxConcurrency: this.options.maxConcurrency,\n      workStealing: this.options.enableWorkStealing\n    });\n  }\n  \n  /**\n   * Execute async function with priority\n   */\n  async execute(fn, priority = TASK_PRIORITY.NORMAL, context = {}) {\n    return new Promise((resolve, reject) => {\n      const task = {\n        id: this.generateTaskId(),\n        fn,\n        context,\n        resolve,\n        reject,\n        createdAt: performance.now()\n      };\n      \n      let scheduled;\n      if (this.scheduler) {\n        scheduled = this.scheduler.schedule(task, priority);\n      } else {\n        scheduled = this.taskQueue.enqueue(task, priority);\n      }\n      \n      if (!scheduled) {\n        reject(new Error('Task queue is full'));\n      }\n    });\n  }\n  \n  /**\n   * Execute multiple tasks in parallel\n   */\n  async executeAll(tasks, priority = TASK_PRIORITY.NORMAL) {\n    const promises = tasks.map(task => \n      this.execute(task.fn, task.priority || priority, task.context)\n    );\n    \n    return Promise.allSettled(promises);\n  }\n  \n  /**\n   * Execute tasks in batches\n   */\n  async executeBatch(tasks, batchSize = this.options.batchSize, priority = TASK_PRIORITY.NORMAL) {\n    const results = [];\n    \n    for (let i = 0; i < tasks.length; i += batchSize) {\n      const batch = tasks.slice(i, i + batchSize);\n      const batchResults = await this.executeAll(batch, priority);\n      results.push(...batchResults);\n    }\n    \n    return results;\n  }\n  \n  /**\n   * Process batch of tasks\n   */\n  processTaskBatch() {\n    const maxProcess = Math.min(\n      this.options.batchSize,\n      this.options.maxConcurrency - this.activeExecutions.size\n    );\n    \n    let processed = 0;\n    \n    while (processed < maxProcess && this.activeExecutions.size < this.options.maxConcurrency) {\n      let task;\n      \n      if (this.scheduler) {\n        // Try to get task from each worker queue\n        for (let i = 0; i < this.options.maxConcurrency && !task; i++) {\n          task = this.scheduler.getTask(i);\n          if (task) {\n            task.workerIndex = i;\n          }\n        }\n      } else {\n        task = this.taskQueue.dequeue();\n      }\n      \n      if (!task) break;\n      \n      this.executeTask(task);\n      processed++;\n    }\n  }\n  \n  /**\n   * Execute individual task\n   */\n  async executeTask(task) {\n    const execution = {\n      id: task.id,\n      startTime: performance.now(),\n      task\n    };\n    \n    this.activeExecutions.add(execution);\n    this.metrics.concurrentExecutions = this.activeExecutions.size;\n    \n    try {\n      // Execute the task function\n      const result = await task.fn(task.context);\n      \n      // Record successful execution\n      const executionTime = performance.now() - execution.startTime;\n      this.recordExecution(executionTime, task.workerIndex);\n      \n      task.resolve(result);\n      \n    } catch (error) {\n      logger.error('Task execution failed', {\n        taskId: task.id,\n        error: error.message\n      });\n      \n      this.metrics.totalErrors++;\n      task.reject(error);\n      \n    } finally {\n      this.activeExecutions.delete(execution);\n      this.metrics.concurrentExecutions = this.activeExecutions.size;\n    }\n  }\n  \n  /**\n   * Record execution metrics\n   */\n  recordExecution(executionTime, workerIndex) {\n    this.metrics.totalExecuted++;\n    this.metrics.avgExecutionTime = \n      (this.metrics.avgExecutionTime * (this.metrics.totalExecuted - 1) + executionTime) / \n      this.metrics.totalExecuted;\n    \n    // Update throughput (tasks per second)\n    this.metrics.throughput = this.metrics.totalExecuted / (Date.now() / 1000);\n    \n    // Report to scheduler if applicable\n    if (this.scheduler && workerIndex !== undefined) {\n      this.scheduler.reportTaskCompletion(workerIndex, executionTime);\n    }\n  }\n  \n  /**\n   * Generate unique task ID\n   */\n  generateTaskId() {\n    return `task_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n  }\n  \n  /**\n   * Get executor statistics\n   */\n  getStats() {\n    const baseStats = {\n      metrics: this.metrics,\n      activeExecutions: this.activeExecutions.size,\n      maxConcurrency: this.options.maxConcurrency\n    };\n    \n    if (this.scheduler) {\n      baseStats.scheduler = this.scheduler.getStats();\n    } else {\n      baseStats.queue = this.taskQueue.getStats();\n    }\n    \n    return baseStats;\n  }\n  \n  /**\n   * Shutdown executor\n   */\n  async shutdown(timeout = 5000) {\n    // Stop processing new tasks\n    if (this.executionTimer) {\n      clearInterval(this.executionTimer);\n    }\n    \n    // Wait for active executions to complete\n    const deadline = Date.now() + timeout;\n    \n    while (this.activeExecutions.size > 0 && Date.now() < deadline) {\n      await new Promise(resolve => setTimeout(resolve, 100));\n    }\n    \n    // Shutdown scheduler\n    if (this.scheduler) {\n      this.scheduler.shutdown();\n    }\n    \n    logger.info('Ultra-async executor shutdown completed', {\n      totalExecuted: this.metrics.totalExecuted,\n      avgExecutionTime: this.metrics.avgExecutionTime\n    });\n  }\n}\n\n/**\n * Coroutine-style async generator utilities\n */\nexport class AsyncCoroutine {\n  constructor(generator) {\n    this.generator = generator;\n    this.isRunning = false;\n    this.result = null;\n    this.error = null;\n  }\n  \n  /**\n   * Run coroutine to completion\n   */\n  async run(...args) {\n    if (this.isRunning) {\n      throw new Error('Coroutine is already running');\n    }\n    \n    this.isRunning = true;\n    \n    try {\n      const iterator = this.generator(...args);\n      let current = await iterator.next();\n      \n      while (!current.done) {\n        // Yield control back to event loop\n        await new Promise(resolve => setImmediate(resolve));\n        current = await iterator.next();\n      }\n      \n      this.result = current.value;\n      return this.result;\n      \n    } catch (error) {\n      this.error = error;\n      throw error;\n    } finally {\n      this.isRunning = false;\n    }\n  }\n  \n  /**\n   * Check if coroutine is running\n   */\n  running() {\n    return this.isRunning;\n  }\n}\n\n/**\n * Create coroutine from async generator\n */\nexport function createCoroutine(generator) {\n  return new AsyncCoroutine(generator);\n}\n\n/**\n * Async iterator utilities\n */\nexport class AsyncIteratorUtils {\n  /**\n   * Transform async iterator with mapping function\n   */\n  static async* map(iterator, mapFn) {\n    for await (const item of iterator) {\n      yield await mapFn(item);\n    }\n  }\n  \n  /**\n   * Filter async iterator\n   */\n  static async* filter(iterator, filterFn) {\n    for await (const item of iterator) {\n      if (await filterFn(item)) {\n        yield item;\n      }\n    }\n  }\n  \n  /**\n   * Batch async iterator items\n   */\n  static async* batch(iterator, batchSize) {\n    let batch = [];\n    \n    for await (const item of iterator) {\n      batch.push(item);\n      \n      if (batch.length >= batchSize) {\n        yield batch;\n        batch = [];\n      }\n    }\n    \n    if (batch.length > 0) {\n      yield batch;\n    }\n  }\n  \n  /**\n   * Take first N items from async iterator\n   */\n  static async* take(iterator, count) {\n    let taken = 0;\n    \n    for await (const item of iterator) {\n      if (taken >= count) break;\n      yield item;\n      taken++;\n    }\n  }\n}\n\nexport default {\n  TASK_PRIORITY,\n  PriorityTaskQueue,\n  WorkStealingScheduler,\n  UltraAsyncExecutor,\n  AsyncCoroutine,\n  createCoroutine,\n  AsyncIteratorUtils\n};"